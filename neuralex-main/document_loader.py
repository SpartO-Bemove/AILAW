"""
–ú–æ–¥—É–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""
import logging
import os
import hashlib
from typing import List, Dict, Optional
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False
    logger.warning("PyMuPDF –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, PDF —Ñ–∞–π–ª—ã –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è")

try:
    import docx
    PYTHON_DOCX_AVAILABLE = True
except ImportError:
    PYTHON_DOCX_AVAILABLE = False
    logger.warning("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, DOCX —Ñ–∞–π–ª—ã –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è")

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

logger = logging.getLogger(__name__)

class DocumentLoader:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ documents/"""
    
    def __init__(self, documents_path: str = "documents"):
        self.documents_path = Path(documents_path)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
        self.supported_extensions = {'.txt', '.md'}
        if PYMUPDF_AVAILABLE:
            self.supported_extensions.add('.pdf')
        if PYTHON_DOCX_AVAILABLE:
            self.supported_extensions.add('.docx')
            
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        self._create_directories()
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        directories = ['laws', 'codes', 'articles', 'court_practice']
        for directory in directories:
            (self.documents_path / directory).mkdir(parents=True, exist_ok=True)
    
    def get_file_hash(self, file_path: Path) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ö—ç—à —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ö—ç—à–∞ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return ""
    
    def extract_text_from_file(self, file_path: Path) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ —Ç–∏–ø–∞"""
        try:
            extension = file_path.suffix.lower()
            
            if extension == '.txt' or extension == '.md':
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            
            elif extension == '.pdf':
                if not PYMUPDF_AVAILABLE:
                    logger.warning(f"PyMuPDF –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º PDF —Ñ–∞–π–ª: {file_path}")
                    return None
                
                try:
                    doc = fitz.open(file_path)
                    text = ""
                    for page in doc:
                        text += page.get_text()
                    doc.close()
                    return text
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF {file_path}: {e}")
                    return None
            
            elif extension == '.docx':
                if not PYTHON_DOCX_AVAILABLE:
                    logger.warning(f"python-docx –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º DOCX —Ñ–∞–π–ª: {file_path}")
                    return None
                
                try:
                    doc = docx.Document(file_path)
                    text = ""
                    for paragraph in doc.paragraphs:
                        text += paragraph.text + "\n"
                    return text
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ DOCX {file_path}: {e}")
                    return None
            
            else:
                logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {extension}")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ {file_path}: {e}")
            return None
    
    def load_documents_from_directory(self, directory: Path, category: str) -> List[Document]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        documents = []
        
        if not directory.exists():
            logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return documents
        
        for file_path in directory.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in self.supported_extensions:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 10 –ú–ë)
                    if file_path.stat().st_size > 10 * 1024 * 1024:
                        logger.warning(f"–§–∞–π–ª {file_path.name} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>10MB), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    text = self.extract_text_from_file(file_path)
                    if text and len(text.strip()) > 50:  # –ú–∏–Ω–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
                        chunks = self.text_splitter.split_text(text)
                        
                        for i, chunk in enumerate(chunks):
                            doc = Document(
                                page_content=chunk,
                                metadata={
                                    'source': str(file_path),
                                    'filename': file_path.name,
                                    'category': category,
                                    'chunk_id': i,
                                    'file_hash': self.get_file_hash(file_path)
                                }
                            )
                            documents.append(doc)
                        
                        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {file_path.name} ({len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤)")
                    else:
                        logger.warning(f"–§–∞–π–ª {file_path.name} –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
        return documents
    
    def load_all_documents(self) -> List[Document]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        all_documents = []
        
        categories = {
            'laws': '–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã',
            'codes': '–ö–æ–¥–µ–∫—Å—ã –†–§', 
            'articles': '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Å—Ç–∞—Ç—å–∏',
            'court_practice': '–°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞'
        }
        
        for folder, category in categories.items():
            directory = self.documents_path / folder
            documents = self.load_documents_from_directory(directory, category)
            all_documents.extend(documents)
            
            if documents:
                logger.info(f"üìö –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_documents)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        return all_documents
    
    def get_documents_stats(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
        stats = {
            'total_files': 0,
            'categories': {},
            'supported_formats': list(self.supported_extensions)
        }
        
        categories = ['laws', 'codes', 'articles', 'court_practice']
        
        for category in categories:
            directory = self.documents_path / category
            if directory.exists():
                files = [f for f in directory.iterdir() 
                        if f.is_file() and f.suffix.lower() in self.supported_extensions]
                stats['categories'][category] = len(files)
                stats['total_files'] += len(files)
        
        return stats